{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Twin evaluation example\nThis example shows how you can use PyTwin to load and evaluate a Twin model.\nThe model consists in a coupled clutches with 4 inputs (applied torque,\n3 clutches opening) and 3 outputs (computed torque on each of the clutches)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"file://_static/coupledClutches.png\" width=\"400pt\" align=\"center\">\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_path = '_static/coupledClutches.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform required imports\nPerform required imports, which includes downloading and importing the\ninput files\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport pandas as pd\nfrom pytwin import TwinModel, download_file, load_data\n\ntwin_file = download_file(\"CoupledClutches_23R1_other.twin\", \"twin_files\")\ncsv_input = download_file(\"CoupledClutches_input.csv\", \"twin_input_files\")\ntwin_config = download_file(\"CoupledClutches_config.json\", \"twin_input_files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Auxiliary functions definition\nPost processing for results comparison.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_result_comparison(step_by_step_results: pd.DataFrame, batch_results: pd.DataFrame):\n    \"\"\"Compare the results obtained from 2 different simulations executed\n    on the same TwinModel. The 2 results dataset are provided as Pandas\n    Dataframe. The function will plot the different results for all the\n    outputs\"\"\"\n    pd.set_option(\"display.precision\", 12)\n    pd.set_option(\"display.max_columns\", 20)\n    pd.set_option(\"display.expand_frame_repr\", False)\n\n    # Plotting the runtime outputs\n    columns = step_by_step_results.columns[1::]\n    result_sets = 2  # Results from only step-by-step, batch_mode\n    fig, ax = plt.subplots(ncols=result_sets, nrows=len(columns), figsize=(18, 7))\n    if len(columns) == 1:\n        single_column = True\n    else:\n        single_column = False\n\n    fig.subplots_adjust(hspace=0.5)\n    fig.set_tight_layout({\"pad\": 0.0})\n\n    for ind, col_name in enumerate(columns):\n        # Plot runtime results\n        if single_column:\n            axes0 = ax[0]\n            axes1 = ax[1]\n\n        else:\n            axes0 = ax[ind, 0]\n            axes1 = ax[ind, 1]\n\n        step_by_step_results.plot(x=0, y=col_name, ax=axes0, ls=\":\", color=\"g\", title=\"Twin Runtime - Step by Step\")\n        axes0.legend(loc=2)\n        axes0.set_xlabel(\"Time [s]\")\n\n        # Plot Twin batch mode csv results\n        batch_results.plot(x=0, y=col_name, ax=axes1, ls=\"-.\", color=\"g\", title=\"Twin Runtime - Batch Mode\")\n        axes1.legend(loc=2)\n        axes1.set_xlabel(\"Time [s]\")\n\n        if ind > 0:\n            axes0.set_title(\"\")\n            axes1.set_title(\"\")\n\n    # Show plot\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the Twin Runtime and external CSV file\nLoading the Twin Runtime and instantiating it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Loading model: {}\".format(twin_file))\ntwin_model = TwinModel(twin_file)\ntwin_model_input_df = load_data(csv_input)\ndata_dimensions = twin_model_input_df.shape\nnumber_of_datapoints = data_dimensions[0] - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up the initial settings of the Twin and initializing it\nDefining the initial inputs of the Twin, initializing it and collecting\nthe initial outputs values\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "twin_model.initialize_evaluation(json_config_filepath=twin_config)\noutputs = [twin_model.evaluation_time]\nfor item in twin_model.outputs:\n    outputs.append(twin_model.outputs[item])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step by step simulation mode\nLooping over all the input data, simulating the Twin one time step at a\ntime and collecting corresponding outputs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sim_output_list_step = [outputs]\ndata_index = 0\nwhile data_index < number_of_datapoints:\n    # Gets the stop time of the current simulation step\n    time_end = twin_model_input_df.iloc[data_index + 1][0]\n    step = time_end - twin_model.evaluation_time\n    inputs = dict()\n    for column in twin_model_input_df.columns[1::]:\n        inputs[column] = twin_model_input_df[column][data_index]\n    twin_model.evaluate_step_by_step(step_size=step, inputs=inputs)\n    outputs = [twin_model.evaluation_time]\n    for item in twin_model.outputs:\n        outputs.append(twin_model.outputs[item])\n    sim_output_list_step.append(outputs)\n    data_index += 1\nresults_step_pd = pd.DataFrame(sim_output_list_step, columns=[\"Time\"] + list(twin_model.outputs), dtype=float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch simulation mode\nResetting/re-initializing the Twin and running it in batch mode (i.e. passing\nall the input data, simulating all the data points, and collecting all\nthe outputs at once)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_index = 0\ninputs = dict()\nfor column in twin_model_input_df.columns[1::]:\n    inputs[column] = twin_model_input_df[column][data_index]\ntwin_model.initialize_evaluation(inputs=inputs, json_config_filepath=twin_config)\noutputs = [twin_model.evaluation_time]\nfor item in twin_model.outputs:\n    outputs.append(twin_model.outputs[item])\nresults_batch_pd = twin_model.evaluate_batch(twin_model_input_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post processing\nPlotting the different results and saving the image on disk\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_result_comparison(results_step_pd, results_batch_pd)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}