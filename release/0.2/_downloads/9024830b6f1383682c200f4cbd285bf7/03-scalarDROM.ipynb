{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Scalar dynamic ROM Twin evaluation example\nThis example shows how you can use PyTwin to load and evaluate a Twin model.\nThe model is a scalar dynamic ROM created out of a 3D thermal model of a\nHeat Exchanger, having a heat flow as input and three temperature probes\nas outputs. The example shows a workflow for what-if analysis by deploying\na second twin in parallel while simulating the original twin and comparing\nthe different predictions. This is done using the specific functions for saving\nand loading the twin states. It also illustrates the usage of modify_pytwin_working_dir\nto change the default working directory location (%temp%) to a user specified location\nwhere the different logging files will be available.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"file://_static/heatExchangerRS.png\" width=\"400pt\" align=\"center\">\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_path = '_static/scalarDROM.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform required imports\nPerform required imports, which includes downloading and importing the input files\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom pytwin import TwinModel, download_file, load_data, modify_pytwin_working_dir\n\ntwin_file = download_file(\"HX_scalarDRB_23R1_other.twin\", \"twin_files\")\ncsv_input = download_file(\"HX_scalarDRB_input.csv\", \"twin_input_files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Auxiliary functions definition\nPost processing for results comparison.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_result_comparison(step_by_step_results: pd.DataFrame, what_if: pd.DataFrame):\n    \"\"\"Compare the results obtained from 2 different simulations executed on the same TwinModel.\n    The 2 results dataset are provided as Pandas Dataframe. The function will plot the different results for all the\n    outputs\"\"\"\n    pd.set_option(\"display.precision\", 12)\n    pd.set_option(\"display.max_columns\", 20)\n    pd.set_option(\"display.expand_frame_repr\", False)\n\n    # Plotting the runtime outputs\n    columns = step_by_step_results.columns[1::]\n    columns_what_if = what_if.columns[1::]\n    result_sets = 1  # Results from only step-by-step + what-if analysis\n    fig, ax = plt.subplots(ncols=result_sets, nrows=len(columns), figsize=(18, 7))\n    if len(columns) == 1:\n        single_column = True\n    else:\n        single_column = False\n\n    fig.subplots_adjust(hspace=0.5)\n    fig.set_tight_layout({\"pad\": 0.0})\n\n    for ind, col_name in enumerate(columns):\n        # Plot runtime results\n        axes0 = ax[ind]\n\n        step_by_step_results.plot(x=0, y=col_name, ax=axes0, ls=\":\", color=\"g\")\n        axes0.legend(loc=2)\n        axes0.set_xlabel(\"Time [s]\")\n\n        # Plot Twin what-if analysis results\n        what_if.plot(x=0, y=columns_what_if[ind], ax=axes0, ls=\"-.\", color=\"g\", title=\"Twin Runtime - What if analysis\")\n\n        if ind > 0:\n            axes0.set_title(\"\")\n\n    # Show plot\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining external files path\nChanging the working directory (by default in %temp%) to user defined location, and loading the input data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "modify_pytwin_working_dir(os.path.join(os.path.dirname(twin_file), \"pyTwinWorkingDir\"))\n\ntwin_model_input_df = load_data(csv_input)\ndata_dimensions = twin_model_input_df.shape\nnumber_of_datapoints = data_dimensions[0] - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the Twin Runtime and instantiating it\nLoading the Twin Runtime and instantiating it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Loading model: {}\".format(twin_file))\ntwin_model = TwinModel(twin_file)\ntwin_model_what_if = None  # the second twin used for what-if analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up the initial settings of the Twin and initializing it\nDefining the initial inputs of the Twin, initializing it and collecting the initial outputs values\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "twin_model.initialize_evaluation()\noutputs = [twin_model.evaluation_time]\nfor item in twin_model.outputs:\n    outputs.append(twin_model.outputs[item])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step by step simulation mode\nLooping over all the input data, simulating the Twin one time step at a time and collecting corresponding outputs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sim_output_list_step = [outputs]\nsim_what_if_output_list_step = []\ndata_index = 0\nwhile data_index < number_of_datapoints:\n    if data_index == int(number_of_datapoints / 4) and twin_model_what_if is None:\n        # Save the original model's current states\n        twin_model.save_state()\n        # Instantiate a new TwinModel with same twin file and load the saved state\n        twin_model_what_if = TwinModel(twin_file)\n        twin_model_what_if.load_state(model_id=twin_model.id, evaluation_time=twin_model.evaluation_time)\n        sim_what_if_output_list_step.append(outputs)\n\n    # Gets the stop time of the current simulation step\n    time_end = twin_model_input_df.iloc[data_index + 1][0]\n    step = time_end - twin_model.evaluation_time\n    inputs = dict()\n    for column in twin_model_input_df.columns[1::]:\n        inputs[column] = twin_model_input_df[column][data_index]\n    twin_model.evaluate_step_by_step(step_size=step, inputs=inputs)\n    outputs = [twin_model.evaluation_time]\n    for item in twin_model.outputs:\n        outputs.append(twin_model.outputs[item])\n    sim_output_list_step.append(outputs)\n    if twin_model_what_if is not None:\n        inputs = dict()\n        for column in twin_model_input_df.columns[1::]:\n            inputs[column] = (\n                twin_model_input_df[column][data_index] * 0.9\n            )  # the second Twin will be evaluated using same inputs reduced by 10%\n        twin_model_what_if.evaluate_step_by_step(step_size=step, inputs=inputs)\n        outputs = [twin_model_what_if.evaluation_time]\n        for item in twin_model_what_if.outputs:\n            outputs.append(twin_model_what_if.outputs[item])\n        sim_what_if_output_list_step.append(outputs)\n    data_index += 1\nresults_step_pd = pd.DataFrame(sim_output_list_step, columns=[\"Time\"] + list(twin_model.outputs), dtype=float)\n\noutputs_names = list(twin_model.outputs)\noutput_names_parallel = []\nfor i in range(0, len(outputs_names)):\n    output_names_parallel.append(outputs_names[i] + \" - what-if : load reduced by 10%\")\nresults_what_if_step_pd = pd.DataFrame(\n    sim_what_if_output_list_step, columns=[\"Time\"] + output_names_parallel, dtype=float\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post processing\nPlotting the different results and saving the image on disk\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_result_comparison(results_step_pd, results_what_if_step_pd)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}