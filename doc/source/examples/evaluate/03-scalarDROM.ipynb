{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Scalar dynamic ROM Twin evaluation example\nThis example shows how you can use PyTwin to load and evaluate a Twin model.\nThe model is a scalar dynamic ROM created out of a 3D thermal model of a\nHeat Exchanger, having a heat flow as input and three temperature probes\nas outputs. The example shows a workflow for what-if analysis by deploying \na second twin in parallel while simulating the original twin and comparing\nthe different predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"file://_static/heatExchangerRS.png\" width=\"400pt\" align=\"center\">\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_path = '_static/scalarDROM.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform required imports\nPerform required imports, which includes downloading and importing the input files\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import platform\nimport os\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom pytwin.evaluate import TwinModel\nfrom pytwin import examples\n\ntwin_file = examples.download_file(\"HX_scalarDRB_23R1_other.twin\", \"twin_files\")\ncsv_input = examples.download_file(\"HX_scalarDRB_input.csv\", \"twin_input_files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Auxiliary functions definition\nPost processing for results comparison.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_result_comparison(step_by_step_results: pd.DataFrame, what_if: pd.DataFrame):\n    \"\"\"Compare the results obtained from 2 different simulations executed on the same TwinModel.\n    The 2 results dataset are provided as Pandas Dataframe. The function will plot the different results for all the\n    outputs and save the plot as a file \"results.png\" \"\"\"\n    pd.set_option('display.precision', 12)\n    pd.set_option('display.max_columns', 20)\n    pd.set_option('display.expand_frame_repr', False)\n\n    # Plotting the runtime outputs\n    columns = step_by_step_results.columns[1::]\n    columns_what_if = what_if.columns[1::]\n    result_sets = 1  # Results from only step-by-step + what-if analysis\n    fig, ax = plt.subplots(ncols=result_sets, nrows=len(columns), figsize=(18, 7))\n    if len(columns) == 1:\n        single_column = True\n    else:\n        single_column = False\n\n    fig.subplots_adjust(hspace=0.5)\n    fig.set_tight_layout({\"pad\": .0})\n\n    for ind, col_name in enumerate(columns):\n        # Plot runtime results\n        axes0 = ax[ind]\n\n        step_by_step_results.plot(x=0, y=col_name, ax=axes0, ls=\":\", color='g')\n        axes0.legend(loc=2)\n        axes0.set_xlabel('Time [s]')\n\n        # Plot Twin what-if analysis results\n        what_if.plot(x=0, y=columns_what_if[ind], ax=axes0, ls=\"-.\", color='g',\n                           title='Twin Runtime - What if analysis')\n\n        if ind > 0:\n            axes0.set_title('')\n\n    # Show plot\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining external files path\nDefining the runtime log path as well as loading the input data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#runtime_log = os.path.join(cur_dir, 'model_{}.log'.format(platform.system()))\ntwin_model_input_df = examples.load_data(csv_input)\ndata_dimensions = twin_model_input_df.shape\nnumber_of_datapoints = data_dimensions[0] - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the Twin Runtime and instantiating it\nLoading the Twin Runtime and instantiating it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Loading model: {}'.format(twin_file))\ntwin_model = TwinModel(twin_file)\ntwin_model_what_if = None  # the second twin used for what-if analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up the initial settings of the Twin and initializing it\nDefining the initial inputs of the Twin, initializing it and collecting the initial outputs values\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "twin_model.initialize_evaluation()\noutputs = [twin_model.evaluation_time]\nfor item in twin_model.outputs:\n    outputs.append(twin_model.outputs[item])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step by step simulation mode\nLooping over all the input data, simulating the Twin one time step at a time and collecting corresponding outputs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sim_output_list_step = [outputs]\nsim_what_if_output_list_step = []\ndata_index = 0\nwhile data_index < number_of_datapoints:\n    if data_index == int(number_of_datapoints / 2) and twin_model_what_if is None:\n        filename = f'checkpoint.bin'\n        #CUR_DIR = os.path.abspath(os.path.dirname(os.path.realpath(__file__))) #TODO treat cur_dir issue for doc\n        #twin_state_file = os.path.join(CUR_DIR, filename)\n        #twin_model._twin_runtime.twin_save_state(twin_state_file)\n        twin_model_what_if = TwinModel(twin_file)\n        twin_model_what_if.initialize_evaluation()\n        #twin_model_what_if._twin_runtime.twin_load_state(twin_state_file)\n        twin_model_what_if._evaluation_time = twin_model.evaluation_time\n        sim_what_if_output_list_step.append(outputs)\n\n\n    # Gets the stop time of the current simulation step\n    time_end = twin_model_input_df.iloc[data_index + 1][0]\n    step = time_end - twin_model.evaluation_time\n    inputs = dict()\n    for column in twin_model_input_df.columns[1::]:\n        inputs[column] = twin_model_input_df[column][data_index]\n    twin_model.evaluate_step_by_step(step_size=step, inputs=inputs)\n    outputs = [twin_model.evaluation_time]\n    for item in twin_model.outputs:\n        outputs.append(twin_model.outputs[item])\n    sim_output_list_step.append(outputs)\n    if twin_model_what_if is not None:\n        inputs = dict()\n        for column in twin_model_input_df.columns[1::]:\n            inputs[column] = twin_model_input_df[column][data_index]/2.0 # the second Twin will be evaluated using same\n            # inputs reduced by 50%\n        twin_model_what_if.evaluate_step_by_step(step_size=step, inputs=inputs)\n        outputs = [twin_model_what_if.evaluation_time]\n        for item in twin_model_what_if.outputs:\n            outputs.append(twin_model_what_if.outputs[item])\n        sim_what_if_output_list_step.append(outputs)\n    data_index += 1\nresults_step_pd = pd.DataFrame(sim_output_list_step, columns=['Time'] + list(twin_model.outputs),\n                               dtype=float)\n\noutputs_names = list(twin_model.outputs)\noutput_names_parallel = []\nfor i in range(0,len(outputs_names)):\n    output_names_parallel.append(outputs_names[i]+ ' - what-if : load reduced by 50%')\nresults_what_if_step_pd = pd.DataFrame(sim_what_if_output_list_step, columns=['Time'] + output_names_parallel,\n                                       dtype=float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post processing\nPlotting the different results and saving the image on disk\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_result_comparison(results_step_pd, results_what_if_step_pd)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}